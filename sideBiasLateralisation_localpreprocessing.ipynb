{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1> Load experiment info off the QNAP\n",
    "\n",
    "#load the environment + define the path\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#make data file\n",
    "print(\"Takes <30s. However, it might take >1 mins or so if network is busy...\")\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import main_funcs as mfun\n",
    "import utils_funcs as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from local_analysis import get_info\n",
    "\n",
    "# Get the list of recordings\n",
    "info = get_info(\"C:\\\\Users\\\\Lak Lab\\\\Documents\\\\paqtif\\\\2025-05-20\")\n",
    "\n",
    "# set matlab API\n",
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "print('Matlab engine is set correctly.')\n",
    "\n",
    "# display the detected session\n",
    "print(\"Total Session: \" + str(info.recordingList.shape[0]))\n",
    "info.recordingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1> OPTIONAL Filter for a particular expRef from the info list\n",
    "specific_expRef = '2025-05-20_1_MBL015'\n",
    "\n",
    "# Recreate info object with the specific expRef\n",
    "info.recordingList = info.recordingList[info.recordingList['sessionName'] == specific_expRef].reset_index(drop=True)\n",
    "info.recordingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2>  create + save beh fig\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    session = str(info.recordingList.sessionName[0])\n",
    "    save_path = info.recordingList.analysispathname[0]  # Get the path where to save\n",
    "    save_file = os.path.join(save_path, f\"{session}_behavior_plot.png\")\n",
    "\n",
    "    # Check if file already exists\n",
    "    if os.path.exists(save_file):\n",
    "        print(f\"File already exists for session {session}, skipping visualization\")\n",
    "        print(f\"Existing file: {save_file}\")\n",
    "    else:\n",
    "        try:\n",
    "            # Create figure and get handle\n",
    "            eng.visualiseTrainingGrating2AFC(session, 'Grating2AFC_noTimeline', [], nargout=0)\n",
    "            \n",
    "            # Get the current figure handle\n",
    "            fig = eng.gcf()\n",
    "            \n",
    "            # Save the figure\n",
    "            eng.saveas(fig, save_file, nargout=0)\n",
    "            #eng.close(fig, nargout=0)  # Close the figure\n",
    "            \n",
    "            print(f\"Visualization completed and saved for session {session}\")\n",
    "            print(f\"Saved to: {save_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error when running visualiseTrainingGrating2AFC: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3> Extract PAQ data and create imaging frames file\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append('LakLabAnalysis/Utility')  # Asegurarse que el path estÃ¡ en el sistema\n",
    "from extract_paq_events import extract_paq_data_frame\n",
    "\n",
    "# For every session in  recordingList\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    # Build the path to the PAQ file using glob to find any .paq file\n",
    "    paq_path = os.path.join(info.recordingList.path[ind], 'TwoP', '*.paq')\n",
    "    paq_files = glob.glob(paq_path)\n",
    "    \n",
    "    if paq_files:\n",
    "        print(f\"Processing paq and creating imaging_frames.txt for session: {info.recordingList.sessionName[ind]}\")\n",
    "        for paq_file in paq_files:\n",
    "            try:\n",
    "                # Extract data and create imaging_frames.txt\n",
    "                extract_paq_data_frame(paq_file)\n",
    "                print(f\"imaging_frames.txt created successfully for {os.path.basename(paq_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {os.path.basename(paq_file)}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"No paq files found for session: {info.recordingList.sessionName[ind]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4> Check CSV files \n",
    "# checkOnly needs to be False to create new files with MATLAB GENERIC CODE: GetBehavData.mat\n",
    "checkOnly = False # Make false when there is more behaviour session\n",
    "alignSubtract = True\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "\n",
    "    filenameCSV = info.recordingList.analysispathname[ind] + info.recordingList.sessionName[ind] + '_CorrectedeventTimes.csv'\n",
    "    e_filenameCSV = [f for f in glob.glob(filenameCSV)]\n",
    "    if len(e_filenameCSV)==1:\n",
    "        info.recordingList.loc[ind,'eventTimesExtracted']=1\n",
    "        info.recordingList.loc[ind,'eventTimesPath'] = filenameCSV\n",
    "    else:\n",
    "        if checkOnly:\n",
    "            info.recordingList.loc[ind,'eventTimesExtracted']=0\n",
    "            info.recordingList.loc[ind,'eventTimesPath'] = filenameCSV\n",
    "        else:\n",
    "            try:\n",
    "                filenameTimeline = [f for f in glob.glob(info.recordingList.filepathname[ind]+ '\\\\' + info.recordingList.sessionName[ind] + '_Timeline.mat')]\n",
    "                if  (len(filenameTimeline)>0):\n",
    "                    sessionProfile ='Grating2AFC'\n",
    "                else:\n",
    "                    sessionProfile ='Grating2AFC_noTimeline'\n",
    "                \n",
    "                # Get behaviour trial data from Block.mat file\n",
    "                print(' Extracting time events--> Profile: ' + sessionProfile  +'  Session: ' + info.recordingList.sessionName[ind])\n",
    "                data = eng.getBehavData(info.recordingList.sessionName[ind],sessionProfile)\n",
    "\n",
    "                # Apply correction based on the weights to match the eventTimes\n",
    "                if (alignSubtract) & (len(filenameTimeline)>0) & (info.recordingList.twoP[ind]==True): \n",
    "                    print(' Aligning time events: ' + info.recordingList.sessionName[ind])\n",
    "                    # Get weights to convert from probe to behavioural timebase\n",
    "                    twoPpath = info.recordingList.path[ind] + '\\\\TwoP'\n",
    "                    sessionName = info.recordingList.sessionName[ind]\n",
    "                    figsavepath = info.recordingList.analysispathname[ind]\n",
    "                    dataCorrected, variance = eng.applySubtractionCorrection (data, twoPpath ,sessionName, True, figsavepath, nargout=2)\n",
    "                    info.recordingList.loc[ind,'variance'] = variance\n",
    "\n",
    "                    # Apply correction to the signal\n",
    "                    data = dataCorrected\n",
    "                    \n",
    "                # Save the file\n",
    "                eng.writetable(data, filenameCSV, nargout=0)\n",
    "                info.recordingList.loc[ind,'eventTimesExtracted']=1\n",
    "            except:\n",
    "                print(str(ind) + ' - FAILED: Extracting time events: ' + info.recordingList.sessionName[ind])\n",
    "                info.recordingList.loc[ind,'eventTimesExtracted']=0\n",
    "\n",
    "# display the output\n",
    "print( \"Behaviour trial data extraction completed: \" + \n",
    "      str(info.recordingList.eventTimesExtracted.sum()) +\"/\" + str(info.recordingList.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a> SANDRA'S settings for suite2p\n",
    "# for GCaMP6s\n",
    "#diameter_um = 7.9\n",
    "ops = {\n",
    "        'batch_size': 200, # reduce if running out of RAM        \n",
    "        'fast_disk': 'D:\\\\suite2p_binaries',\n",
    "        'delete_bin': False, # whether to delete binary file after processing\n",
    "        'move_bin': True, # moves temp data.bin from fast_disk to save_path if save_path!=fast_disk\n",
    "        'diameter': 14, # this is the main parameter for cell detection, 2-dimensional if Y and X are different (e.g. [6 12])\n",
    "        # main settings\n",
    "        'nplanes' : 1, # each tiff has these many planes in sequence\n",
    "        'nchannels' : 1, # each tiff has these many channels per plane\n",
    "        'functional_chan' : 1, # this channel is used to extract functional ROIs (1-based)\n",
    "        'tau':  1.25, # this is the main parameter for deconvolution (1.25-1.5 for gcamp6s)\n",
    "        'fs': 30, # sampling rate (total across planes, will auto-change from .csv)\n",
    "        # output settings\n",
    "        'save_mat': True, # whether to save output as matlab files\n",
    "        'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "        'save_NWB': 0.0,\n",
    "        'aspect': 1.0,\n",
    "        'do_bidiphase': False,\n",
    "        'bidiphase': 0,\n",
    "        'bidi_corrected': True,\n",
    "\n",
    "        # registration settings\n",
    "        'do_registration': True, # whether to register data\n",
    "        'two_step_registration': 0.0,\n",
    "        'keep_movie_raw': False,\n",
    "        'nimg_init': 500, # subsampled frames for finding reference image\n",
    "        'batch_size': 500,\n",
    "        'maxregshift': 0.1, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "        'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "        'reg_tif': False, # whether to save registered tiffs\n",
    "        'subpixel' : 10, # precision of subpixel registration (1/subpixel steps)\n",
    "        'smooth_sigma_time': 0.0,\n",
    "        'smooth_sigma': 1.15,\n",
    "        'th_badframes': 1.0,\n",
    "        'norm_frames': True,\n",
    "        'force_refImg': False,\n",
    "        'pad_fft': False,\n",
    "\n",
    "        #Non-rigid\n",
    "        'nonrigid': True,\n",
    "        'block_size': [128, 128],\n",
    "        'snr_thresh': 1.2,\n",
    "        'maxregshiftNR': 5.0,\n",
    "\n",
    "        #1P\n",
    "        '1Preg': False,\n",
    "        'spatial_hp_reg': 42.0,\n",
    "        'pre_smooth': 0.0,\n",
    "        'spatial_taper': 40.0,\n",
    "        \n",
    "        # Functional cell detection settings\n",
    "        'roidetect': True,\n",
    "        'spikedetect': True,\n",
    "        'sparse_mode': True,\n",
    "        'spatial_scale': 0,\n",
    "        'connected': True, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "        # 'navg_frames_svd': 5000, # max number of binned frames for the SVD\n",
    "        # 'nsvd_for_roi': 1000, # max number of SVD components to keep for ROI detection\n",
    "        'max_iterations': 30, # maximum number of iterations to do cell detection\n",
    "        # 'ratio_neuropil': 6., # ratio between neuropil basis size and cell radius\n",
    "        # 'ratio_neuropil_to_cell': 3, # minimum ratio between neuropil radius and cell radius\n",
    "        # 'tile_factor': 1., # use finer (>1) or coarser (<1) tiles for neuropil estimation during cell detection\n",
    "        'threshold_scaling': 0, # adjust the automatically determined threshold by this scalar multiplier\n",
    "        'max_overlap': 0.75, # cells with more overlap than this get removed during triage, before refinement\n",
    "        'high_pass': 100.0,\n",
    "        'spatial_hp_detect': 25.0,\n",
    "        'denoise': 0.0,\n",
    "        \n",
    "        #Anatomical detection\n",
    "        'anatomical_only': 3,\n",
    "        #'diameter': [10], #14, #in pixels; be the equivalent of 8 um ? 15 um? \n",
    "        'cellprob_threshold': -6.0,\n",
    "        'flow_threshold': 0.0,\n",
    "        'spatial_hp_cp': 0.0,\n",
    "        'pretrained_model': 'cyto',\n",
    "        \n",
    "        # Extraction/Neuropil & Classify/Deconvolute\n",
    "        'soma_crop': 1.0,\n",
    "        'neuropil_extract': True,\n",
    "        'inner_neuropil_radius': 2,\n",
    "        'min_neuropil_pixels': 350,\n",
    "        # 'lam_percentile': 50.0,  #not listed in ops settings dialog\n",
    "        'allow_overlap': True,\n",
    "        'use_builtin_classifier': False,\n",
    "        'classifier_path': '',\n",
    "        # 'chan2_thres': 0.65, #not listed in ops settings dialog\n",
    "        # 'baseline': 'maximin',  #not listed in ops settings dialog\n",
    "        'win_baseline': 60.0,\n",
    "        'sig_baseline': 10.0,\n",
    "        # 'prctile_baseline': 8.0, #not listed in ops settings dialog\n",
    "        'neucoeff': 0.7,\n",
    "      }\n",
    "ops_mCh = {\n",
    "        #Anatomical detection\n",
    "        'anatomical_only': 4, ##MAX PROJECTION\n",
    "        'diameter': 15, ##STRICTER TO REALLY JUST GET WHOLE CELLS\n",
    "        'cellprob_threshold': -6.0,\n",
    "        'flow_threshold': 1.5, #STRICTER\n",
    "        'spatial_hp_cp': 0.0,\n",
    "        'pretrained_model': 'cyto',\n",
    "      }\n",
    "\n",
    "ops_CTb = {\n",
    "        #Anatomical detection\n",
    "        'anatomical_only': 2, ##Mean PROJECTION\n",
    "        'diameter': 15, ##STRICTER TO REALLY JUST GET WHOLE CELLS\n",
    "        'cellprob_threshold': -6.0,\n",
    "        'flow_threshold': 0, #less strict\n",
    "        'spatial_hp_cp': 0.0,\n",
    "        'pretrained_model': 'cyto',\n",
    "      }\n",
    "\n",
    "#imagingParams_path = os.path.join(info.recordingListPath, \"helperfiles\", \"2025-01_ImagingLogs_SAT017_AMRev.csv\").replace('\\\\', '/')\n",
    "#imagingParams = pd.read_csv(imagingParams_path)\n",
    "#sessionDates = [session[:10] for session in imagingParams['session']]\n",
    "errorLog = []\n",
    "remake = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a> default settings for Suite2p analysis\n",
    "ops = {\n",
    "        'batch_size': 500, # reduce if running out of RAM\n",
    "        'fast_disk': 'D:\\\\suite2p_binaries', # used to store temporary binary file, defaults to save_path0 (set as a string NOT a list)\n",
    "        #'fast_disk': os.path.expanduser('~/suite2p_binaries'), # used to store temporary binary file, defaults to save_path0 (set as a string NOT a list)\n",
    "         #'save_path0': '/media/jamesrowland/DATA/plab/suite_2p', # stores results, defaults to first item in data_path\n",
    "        'delete_bin': False, # whether to delete binary file after processing\n",
    "        # main settings\n",
    "        'nplanes' : 1, # each tiff has these many planes in sequence\n",
    "        'nchannels' : 1, # each tiff has these many channels per plane\n",
    "        'functional_chan' : 1, # this channel is used to extract functional ROIs (1-based)\n",
    "        'diameter': 16, # this is the main parameter for cell detection, 2-dimensional if Y and X are different (e.g. [6 12])\n",
    "        'tau':  1.25, # this is the main parameter for deconvolution (1.25-1.5 for gcamp6s)\n",
    "        'fs': 30.,  # sampling rate (total across planes)\n",
    "        # output settings\n",
    "        'save_mat': True, # whether to save output as matlab files\n",
    "        'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "        # parallel settings\n",
    "        'num_workers': 0, # 0 to select num_cores, -1 to disable parallelism, N to enforce value\n",
    "        'num_workers_roi': 0, # 0 to select number of planes, -1 to disable parallelism, N to enforce value\n",
    "        # registration settings\n",
    "        'do_registration': True, # whether to register data\n",
    "        'nimg_init': 500, # subsampled frames for finding reference image\n",
    "        'maxregshift': 0.1, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "        'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "        'reg_tif': True, # whether to save registered tiffs\n",
    "        'subpixel' : 10, # precision of subpixel registration (1/subpixel steps)\n",
    "        # cell detection settings\n",
    "        'connected': True, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "        #'navg_frames_svd': 5000, # max number of binned frames for the SVD\n",
    "        #'nsvd_for_roi': 1000, # max number of SVD components to keep for ROI detection\n",
    "        'max_iterations': 30, # maximum number of iterations to do cell detection\n",
    "        #'ratio_neuropil': 6., # ratio between neuropil basis size and cell radius\n",
    "        #'ratio_neuropil_to_cell': 3, # minimum ratio between neuropil radius and cell radius\n",
    "        #'tile_factor': 1., # use finer (>1) or coarser (<1) tiles for neuropil estimation during cell detection\n",
    "        'threshold_scaling': 0., # adjust the automatically determined threshold by this scalar multiplier\n",
    "        'max_overlap': 0.75, # cells with more overlap than this get removed during triage, before refinement\n",
    "        'inner_neuropil_radius': 2, # number of pixels to keep between ROI and neuropil donut\n",
    "        'outer_neuropil_radius': np.inf, # maximum neuropil radius\n",
    "        'min_neuropil_pixels': 350, # minimum number of pixels in the neuropil\n",
    "        # deconvolution settings\n",
    "        #'baseline': 'maximin', # baselining mode\n",
    "        'win_baseline': 60., # window for maximin\n",
    "        'sig_baseline': 10., # smoothing constant for gaussian filter\n",
    "        #'prctile_baseline': 8.,# optional (whether to use a percentile baseline)\n",
    "        'neucoeff': .7,  # neuropil coefficient\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b> Run Suite2p\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    # Check if twoP is True\n",
    "    if info.recordingList.twoP[ind]:\n",
    "        tiff_directory = os.path.join(info.recordingList.path[ind], 'TwoP', f\"{info.recordingList.recordingDate[ind]}_t-001\")\n",
    "        suite2p_folder = os.path.join(tiff_directory, 'suite2p')\n",
    "        e_suite2p_folder = [f for f in glob.glob(suite2p_folder)]\n",
    "        if len(e_suite2p_folder)==1:\n",
    "                info.recordingList.loc[ind,'suite2pPath'] = suite2p_folder\n",
    "                print(f\"{info.recordingList.animalID[ind]}{info.recordingList.recordingDate[ind]}: Suite2p is created before\")\n",
    "        else:\n",
    "            db = { \n",
    "                        'data_path':  os.path.join(info.rawPath, info.recordingList.animalID[ind]),\n",
    "                        'tiff_list': glob.glob(os.path.join(tiff_directory, \"*.tif\")),\n",
    "                        'save_folder': suite2p_folder\n",
    "                        }\n",
    "            from suite2p.run_s2p import run_s2p\n",
    "            import time        \n",
    "            t1 = time.time()\n",
    "            opsEnd = run_s2p(ops=ops,db=db)\n",
    "            t2 = time.time()\n",
    "            print(f\"{info.recordingList.animalID[ind]}: Suite2p is created in {t2 - t1} seconds.\")\n",
    "    else:\n",
    "        print(f\"Skipping Suite2p for {info.recordingList.animalID[ind]} - twoP is False\")\n",
    "    \n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6> extract suite2p output\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    # Define the output file path\n",
    "    filenameINFO = os.path.join(info.recordingList.analysispathname[ind], 'imaging-data.pkl')\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if os.path.exists(filenameINFO):\n",
    "        print(f\"File already exists for session {info.recordingList.sessionName[ind]}, skipping extraction\")\n",
    "        print(f\"Existing file: {filenameINFO}\")\n",
    "    else:\n",
    "        try:\n",
    "            # Read suite2p\n",
    "            s2p_path = os.path.join(info.recordingList.path[ind], 'TwoP', f\"{info.recordingList.recordingDate[ind]}_t-001\", 'suite2p', 'plane0')\n",
    "            if os.path.exists(s2p_path):\n",
    "                print('Extracting...')\n",
    "                ops = np.load(os.path.join(s2p_path, 'ops.npy'), allow_pickle=True)\n",
    "                ops = ops.item()\n",
    "                FrameNums = ops['frames_per_file']\n",
    "                filelist = ops['filelist']\n",
    "                isCell = np.load(os.path.join(s2p_path, 'iscell.npy'), allow_pickle=True)\n",
    "\n",
    "                # Load the suite2p\n",
    "                flu_raw_subtracted, spks, stat = utils.s2p_loader(s2p_path)\n",
    "                flu = utils.dfof2(flu_raw_subtracted)\n",
    "\n",
    "                # Cut each session & save it in the analysis-session folder\n",
    "                imaging_data = {\n",
    "                    \"n_frames\": FrameNums,\n",
    "                    \"flu\": flu,\n",
    "                    \"spks\": spks,\n",
    "                    \"stat\": stat,\n",
    "                }\n",
    "                \n",
    "                print(f\"{filenameINFO} --> # of cells: {flu.shape[0]} # of frames: {flu.shape[1]}\")\n",
    "                with open(filenameINFO, 'wb') as f:\n",
    "                    pickle.dump(imaging_data, f)\n",
    "                print(f\"Successfully saved imaging data for session {info.recordingList.sessionName[ind]}\")\n",
    "            else:\n",
    "                print(f\"Suite2p path not found: {s2p_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {info.recordingList.sessionName[ind]}: {str(e)}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7> Visualize cells\n",
    "# Filter cells with probability > 0.5\n",
    "prob_threshold = 0.5\n",
    "cell_indices = np.where((isCell[:,0] == 1) & (isCell[:,1] > prob_threshold))[0]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Show mean image\n",
    "ax.imshow(ops['meanImg'], cmap='binary_r')\n",
    "\n",
    "# Load stat.npy to get cell coordinates\n",
    "stat = np.load(os.path.join(s2p_path, 'stat.npy'), allow_pickle=True)\n",
    "\n",
    "# Generate random colors for each cell\n",
    "colors = np.random.rand(len(cell_indices), 3)\n",
    "\n",
    "# Draw ROIs of filtered cells\n",
    "for idx, cell_number in enumerate(cell_indices):\n",
    "    stat_cell = stat[cell_number]\n",
    "    ypix = [stat_cell['ypix'][i] for i in range(len(stat_cell['ypix'])) if not stat_cell['overlap'][i]]\n",
    "    xpix = [stat_cell['xpix'][i] for i in range(len(stat_cell['xpix'])) if not stat_cell['overlap'][i]]\n",
    "    ax.plot(xpix, ypix, '.', markersize=1, alpha=0.7, color=colors[idx])\n",
    "\n",
    "ax.set_title(f\"Detected cells (prob > {prob_threshold}): {len(cell_indices)}\")\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Also show enhanced image (meanImgE) which might be clearer\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(ops['meanImgE'], cmap='binary_r')\n",
    "\n",
    "# Draw ROIs of filtered cells\n",
    "for idx, cell_number in enumerate(cell_indices):\n",
    "    stat_cell = stat[cell_number]\n",
    "    ypix = [stat_cell['ypix'][i] for i in range(len(stat_cell['ypix'])) if not stat_cell['overlap'][i]]\n",
    "    xpix = [stat_cell['xpix'][i] for i in range(len(stat_cell['xpix'])) if not stat_cell['overlap'][i]]\n",
    "    ax.plot(xpix, ypix, '.', markersize=1, alpha=0.7, color=colors[idx])\n",
    "\n",
    "ax.set_title(f\"Detected cells (prob > {prob_threshold}): {len(cell_indices)}\")\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8> Check Suite2p extraction\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    filenameDFF = info.recordingList.analysispathname[ind] + 'imaging-data.pkl'\n",
    "    e_filenameDFF = [f for f in glob.glob(filenameDFF)]\n",
    "    if len(e_filenameDFF)>0:\n",
    "        info.recordingList.loc[ind,'imagingDataExtracted']=1\n",
    "        info.recordingList.loc[ind,'imagingDataPath'] = filenameDFF\n",
    "    else:\n",
    "        info.recordingList.loc[ind,'imagingDataExtracted']=0\n",
    "        info.recordingList.loc[ind,'imagingDataPath'] = filenameDFF\n",
    "\n",
    "# display the output\n",
    "print( \"Imaging data extraction completed: \" + \n",
    "      str(info.recordingList.imagingDataExtracted.sum()) +\"/\" + str(info.recordingList.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9> check imaging-data.pkl\n",
    "\n",
    "import pickle\n",
    "\n",
    "# File path\n",
    "file_path = info.recordingList.analysispathname[ind] + 'imaging-data.pkl'\n",
    "\n",
    "try:\n",
    "    # Open and load the pickle file\n",
    "    with open(file_path, 'rb') as f:\n",
    "        imaging_data = pickle.load(f)\n",
    "    \n",
    "    # Show the keys of the dictionary\n",
    "    print(\"Keys available in the file:\")\n",
    "    print(imaging_data.keys())\n",
    "    \n",
    "    # Show basic data information\n",
    "    print(\"\\nData information:\")\n",
    "    print(f\"Number of frames: {imaging_data['n_frames']}\")\n",
    "    print(f\"Flu shape: {imaging_data['flu'].shape}\")\n",
    "    print(f\"Spks shape: {imaging_data['spks'].shape}\")\n",
    "    print(f\"Number of elements in stat: {len(imaging_data['stat'])}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found in {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error opening file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10> Save info into the analysis folder\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump(info, f)\n",
    "print('All should be done!!')\n",
    "\n",
    "# Save table as CSV\n",
    "recordingList = info.recordingList\n",
    "recordingList.to_csv( info.analysisPath +'\\\\recordingList.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sideBias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
