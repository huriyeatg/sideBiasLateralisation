{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes <30s. However, it might take >1 mins or so if network is busy...\n",
      "Env: sideBias\n",
      "Computer: Candela Windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lak Lab\\Documents\\Github\\sideBiasLateralisation\\main_funcs.py:148: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'C:/Users/Lak Lab/Documents/Github/sideBiasLateralisation\\analysis\\2023-05-31_OFZ011_1\\' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.recordingList.loc[ind,'analysispathname'] = analysispathname +'\\\\'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Session: 58\n",
      "Matlab engine is set correctly.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#make data file\n",
    "print( \"Takes <30s. However, it might take >1 mins or so if network is busy...\")\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import main_funcs as mfun\n",
    "import utils_funcs as utils # utils is from Vape - catcher file: \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Get the list of recordings\n",
    "info = mfun.analysis()\n",
    "# display the detected session\n",
    "print( \"Total Session: \" +  str(info.recordingList .shape[0]))\n",
    "#info.recordingList.head()\n",
    "\n",
    "# set matlab API\n",
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "print('Matlab engine is set correctly.')\n",
    "\n",
    "# Filter for a particular expRef from the info list\n",
    "specific_expRef = '2025-04-07_1_CMN001'\n",
    "\n",
    "# Recreate info object with the specific expRef\n",
    "info.recordingList = info.recordingList[info.recordingList['sessionName'] == specific_expRef].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animalID</th>\n",
       "      <th>recordingDate</th>\n",
       "      <th>recordingID</th>\n",
       "      <th>sessionName</th>\n",
       "      <th>learningData</th>\n",
       "      <th>twoP</th>\n",
       "      <th>ROI</th>\n",
       "      <th>path</th>\n",
       "      <th>sessionNameWithPath</th>\n",
       "      <th>analysispathname</th>\n",
       "      <th>filepathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFZ011</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-31_1_OFZ011</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Z:/OFZ011\\2023-05-31</td>\n",
       "      <td>Z:/OFZ011\\2023-05-31\\1\\2023-05-31_1_OFZ011_Blo...</td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/OFZ011\\2023-05-31\\1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animalID recordingDate recordingID          sessionName  learningData  twoP  \\\n",
       "0   OFZ011    2023-05-31           1  2023-05-31_1_OFZ011          True  True   \n",
       "\n",
       "   ROI                  path  \\\n",
       "0    0  Z:/OFZ011\\2023-05-31   \n",
       "\n",
       "                                 sessionNameWithPath  \\\n",
       "0  Z:/OFZ011\\2023-05-31\\1\\2023-05-31_1_OFZ011_Blo...   \n",
       "\n",
       "                                    analysispathname            filepathname  \n",
       "0  C:/Users/Lak Lab/Documents/Github/sideBiasLate...  Z:/OFZ011\\2023-05-31\\1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.recordingList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to check the paq file details - change filenamePAQ\n",
    "# import paq2py as paq_reader\n",
    "# import utils_funcs as utils\n",
    "\n",
    "# filenamePAQ =  'Y:\\\\OFZ011\\\\2023-07-07\\\\TwoP\\\\2023-07-07_OFZ011_paq_001.paq'\n",
    "# savepathname = info.recordingList()\n",
    "# paq_data = paq_reader.paq_read( file_path=filenamePAQ, plot=True, save_path=savepathname) \n",
    "# frame_clock = utils.paq_data (paqData, 'reward', threshold_ttl=True, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getBehavData function found\n"
     ]
    }
   ],
   "source": [
    "# Get getBehavData function\n",
    "\n",
    "base_path = os.path.abspath('C:/Users/Lak Lab/Documents/Github/sideBiasLateralisation/LakLabAnalysis')\n",
    "utility_path = os.path.join(base_path, 'Utility')\n",
    "rigbox_path = os.path.abspath('C:/Users/Lak Lab/Documents/Github/sideBiasLateralisation/Rigbox')\n",
    "burgbox_path = os.path.join(rigbox_path, 'cb-tools', 'burgbox')\n",
    "\n",
    "# Add all necessary directories to the path\n",
    "eng.addpath(base_path)\n",
    "eng.addpath(utility_path)\n",
    "eng.addpath(rigbox_path)\n",
    "eng.addpath(burgbox_path)\n",
    "\n",
    "# Check if the function exists\n",
    "try:\n",
    "    eng.eval(\"which getBehavData\", nargout=0)\n",
    "    print(\"getBehavData function found\")\n",
    "except:\n",
    "    print(\"ERROR: getBehavData function not found\")\n",
    "    print(\"Searching in directories:\")\n",
    "    print(\"Base:\", base_path)\n",
    "    print(\"Utility:\", utility_path)\n",
    "    print(\"Rigbox:\", rigbox_path)\n",
    "    print(\"Burgbox:\", burgbox_path)\n",
    "    eng.eval(\"path\", nargout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting time events--> Profile: Value2AFC_noTimeline  Session: 2023-05-31_1_OFZ011\n",
      "Behaviour trial data extraction completed: 1.0/1\n"
     ]
    }
   ],
   "source": [
    "# Check CSV files \n",
    "# checkOnly needs to be False to create new files with MATLAB GENERIC CODE: GetBehavData.mat\n",
    "checkOnly = False # Make false when there is more behaviour session\n",
    "alignSubtract = True\n",
    "#ind = 49\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "#if ind ==49:\n",
    "    filenameCSV = info.recordingList.analysispathname[ind] + info.recordingList.sessionName[ind] + '_CorrectedeventTimes.csv'\n",
    "    e_filenameCSV = [f for f in glob.glob(filenameCSV)]\n",
    "    if len(e_filenameCSV)==1:\n",
    "        info.recordingList.loc[ind,'eventTimesExtracted']=1\n",
    "        info.recordingList.loc[ind,'eventTimesPath'] = filenameCSV\n",
    "    else:\n",
    "        if checkOnly:\n",
    "            info.recordingList.loc[ind,'eventTimesExtracted']=0\n",
    "            info.recordingList.loc[ind,'eventTimesPath'] = filenameCSV\n",
    "        else:\n",
    "            try:\n",
    "                filenameTimeline = [f for f in glob.glob(info.recordingList.filepathname[ind]+ '\\\\' + info.recordingList.sessionName[ind] + '_Timeline.mat')]\n",
    "                if  (len(filenameTimeline)>0):\n",
    "                    sessionProfile ='Value2AFC'\n",
    "                else:\n",
    "                    sessionProfile ='Value2AFC_noTimeline'\n",
    "                \n",
    "                # Get behaviour trial data from Block.mat file\n",
    "                print(' Extracting time events--> Profile: ' + sessionProfile  +'  Session: ' + info.recordingList.sessionName[ind])\n",
    "                data = eng.getBehavData(info.recordingList.sessionName[ind],sessionProfile)\n",
    "\n",
    "                # Apply correction based on the weights to match the eventTimes\n",
    "                if (alignSubtract) & (len(filenameTimeline)>0) & (info.recordingList.twoP[ind]==True): \n",
    "                    print(' Aligning time events: ' + info.recordingList.sessionName[ind])\n",
    "                    # Get weights to convert from probe to behavioural timebase\n",
    "                    twoPpath = info.recordingList.path[ind] + '\\\\TwoP'\n",
    "                    sessionName = info.recordingList.sessionName[ind]\n",
    "                    figsavepath = info.recordingList.analysispathname[ind]\n",
    "                    dataCorrected, variance = eng.applySubtractionCorrection (data, twoPpath ,sessionName, True, figsavepath, nargout=2)\n",
    "                    info.recordingList.loc[ind,'variance'] = variance\n",
    "\n",
    "                    # Apply correction to the signal\n",
    "                    data = dataCorrected\n",
    "                    \n",
    "                # Save the file\n",
    "                eng.writetable(data, filenameCSV, nargout=0)\n",
    "                info.recordingList.loc[ind,'eventTimesExtracted']=1\n",
    "            except:\n",
    "                print(str(ind) + ' - FAILED: Extracting time events: ' + info.recordingList.sessionName[ind])\n",
    "                info.recordingList.loc[ind,'eventTimesExtracted']=0\n",
    "\n",
    "# display the output\n",
    "print( \"Behaviour trial data extraction completed: \" + \n",
    "      str(info.recordingList.eventTimesExtracted.sum()) +\"/\" + str(info.recordingList.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default settings for Suite2p analysis\n",
    "ops = {\n",
    "        'batch_size': 200, # reduce if running out of RAM\n",
    "        'fast_disk': os.path.expanduser('~/suite2p_binaries'), # used to store temporary binary file, defaults to save_path0 (set as a string NOT a list)\n",
    "         #'save_path0': '/media/jamesrowland/DATA/plab/suite_2p', # stores results, defaults to first item in data_path\n",
    "        'delete_bin': False, # whether to delete binary file after processing\n",
    "        # main settings\n",
    "        'nplanes' : 1, # each tiff has these many planes in sequence\n",
    "        'nchannels' : 1, # each tiff has these many channels per plane\n",
    "        'functional_chan' : 1, # this channel is used to extract functional ROIs (1-based)\n",
    "        'diameter': 12, # this is the main parameter for cell detection, 2-dimensional if Y and X are different (e.g. [6 12])\n",
    "        'tau':  1.26, # this is the main parameter for deconvolution (1.25-1.5 for gcamp6s)\n",
    "        'fs': 30.,  # sampling rate (total across planes)\n",
    "        # output settings\n",
    "        'save_mat': True, # whether to save output as matlab files\n",
    "        'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "        # parallel settings\n",
    "        'num_workers': 0, # 0 to select num_cores, -1 to disable parallelism, N to enforce value\n",
    "        'num_workers_roi': 0, # 0 to select number of planes, -1 to disable parallelism, N to enforce value\n",
    "        # registration settings\n",
    "        'do_registration': True, # whether to register data\n",
    "        'nimg_init': 200, # subsampled frames for finding reference image\n",
    "        'maxregshift': 0.1, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "        'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "        'reg_tif': True, # whether to save registered tiffs\n",
    "        'subpixel' : 10, # precision of subpixel registration (1/subpixel steps)\n",
    "        # cell detection settings\n",
    "        'connected': True, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "        'navg_frames_svd': 5000, # max number of binned frames for the SVD\n",
    "        'nsvd_for_roi': 1000, # max number of SVD components to keep for ROI detection\n",
    "        'max_iterations': 20, # maximum number of iterations to do cell detection\n",
    "        'ratio_neuropil': 6., # ratio between neuropil basis size and cell radius\n",
    "        'ratio_neuropil_to_cell': 3, # minimum ratio between neuropil radius and cell radius\n",
    "        'tile_factor': 1., # use finer (>1) or coarser (<1) tiles for neuropil estimation during cell detection\n",
    "        'threshold_scaling': 1., # adjust the automatically determined threshold by this scalar multiplier\n",
    "        'max_overlap': 0.75, # cells with more overlap than this get removed during triage, before refinement\n",
    "        'inner_neuropil_radius': 2, # number of pixels to keep between ROI and neuropil donut\n",
    "        'outer_neuropil_radius': np.inf, # maximum neuropil radius\n",
    "        'min_neuropil_pixels': 350, # minimum number of pixels in the neuropil\n",
    "        # deconvolution settings\n",
    "        'baseline': 'maximin', # baselining mode\n",
    "        'win_baseline': 60., # window for maximin\n",
    "        'sig_baseline': 10., # smoothing constant for gaussian filter\n",
    "        'prctile_baseline': 8.,# optional (whether to use a percentile baseline)\n",
    "        'neucoeff': .7,  # neuropil coefficient\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Suite2p\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    tiff_directory = info.recordingList.path[ind] + '/TwoP/' + info.recordingList.recordingDate[ind] + '_t-*' \n",
    "    suite2p_folder = tiff_directory + '/suite2p'\n",
    "    e_suite2p_folder = [f for f in glob.glob(suite2p_folder)]\n",
    "    if len(e_suite2p_folder)==1:\n",
    "            info.recordingList.loc[ind,'suite2pPath'] = suite2p_folder\n",
    "            print( info.recordingList.animalID[ind] + info.recordingList.recordingDate[ind]': Suite2p is created before')\n",
    "    else:\n",
    "        db = { \n",
    "                    'data_path':  os.path.join(info.rawPath, info.recordingList.animalID[ind]),\n",
    "                    'tiff_list': glob.glob(os.path.join(tiff_directory, \"*.tif\")),\n",
    "                    'save_folder': suite2p_folder\n",
    "                    }\n",
    "        from suite2p.run_s2p import run_s2p\n",
    "        import time        \n",
    "        t1 = time.time()\n",
    "        opsEnd = run_s2p(ops=ops,db=db)\n",
    "        t2 = time.time()\n",
    "        print( info.recordingList.animalID[ind] + ': Suite2p is created in {}'.format(t2 - t1) + 'seconds.')\n",
    "    \n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check suite2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract suite2p output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imaging data extraction completed: 0.0/1\n"
     ]
    }
   ],
   "source": [
    "# Check Suite2p files\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    filenameDFF = info.recordingList.analysispathname[ind] + 'imaging-data.pkl'\n",
    "    e_filenameDFF = [f for f in glob.glob(filenameDFF)]\n",
    "    if len(e_filenameDFF)>0:\n",
    "        info.recordingList.loc[ind,'imagingDataExtracted']=1\n",
    "        info.recordingList.loc[ind,'imagingDataPath'] = filenameDFF\n",
    "    else:\n",
    "        info.recordingList.loc[ind,'imagingDataExtracted']=0\n",
    "        info.recordingList.loc[ind,'imagingDataPath'] = filenameDFF\n",
    "\n",
    "# display the output\n",
    "print( \"Imaging data extraction completed: \" + \n",
    "      str(info.recordingList.imagingDataExtracted.sum()) +\"/\" + str(info.recordingList.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All should be done!!\n"
     ]
    }
   ],
   "source": [
    "# Save info into the analysis folder\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump(info, f)\n",
    "print('All should be done!!')\n",
    "\n",
    "# Save table as CSV\n",
    "recordingList = info.recordingList\n",
    "recordingList.to_csv( info.analysisPath +'\\\\recordingList.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sideBias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
