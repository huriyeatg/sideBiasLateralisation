{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes <30s. However, it might take >1 mins or so if network is busy...\n",
      "Computer: Candela Windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lak Lab\\Documents\\Github\\sideBiasLateralisation\\main_funcs.py:146: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'C:/Users/Lak Lab/Documents/Github/sideBiasLateralisation\\analysis\\2025-01-24_MBL015_1\\' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.recordingList.loc[ind,'analysispathname'] = analysispathname +'\\\\'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Session: 225\n",
      "Matlab engine is set correctly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animalID</th>\n",
       "      <th>recordingDate</th>\n",
       "      <th>recordingID</th>\n",
       "      <th>sessionName</th>\n",
       "      <th>learningData</th>\n",
       "      <th>twoP</th>\n",
       "      <th>path</th>\n",
       "      <th>sessionNameWithPath</th>\n",
       "      <th>blockName</th>\n",
       "      <th>imagingTiffFileNames</th>\n",
       "      <th>analysispathname</th>\n",
       "      <th>filepathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL015\\2025-01-24</td>\n",
       "      <td>Z:/MBL015\\2025-01-24\\1\\2025-01-24_1_MBL015_Blo...</td>\n",
       "      <td>2025-01-24_1_MBL015</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-01-24\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-01-27</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-27_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL015\\2025-01-27</td>\n",
       "      <td>Z:/MBL015\\2025-01-27\\1\\2025-01-27_1_MBL015_Blo...</td>\n",
       "      <td>2025-01-27_1_MBL015</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-01-27\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-28_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL015\\2025-01-28</td>\n",
       "      <td>Z:/MBL015\\2025-01-28\\1\\2025-01-28_1_MBL015_Blo...</td>\n",
       "      <td>2025-01-28_1_MBL015</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-01-28\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-29_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL015\\2025-01-29</td>\n",
       "      <td>Z:/MBL015\\2025-01-29\\1\\2025-01-29_1_MBL015_Blo...</td>\n",
       "      <td>2025-01-29_1_MBL015</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-01-29\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-30_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL015\\2025-01-30</td>\n",
       "      <td>Z:/MBL015\\2025-01-30\\1\\2025-01-30_1_MBL015_Blo...</td>\n",
       "      <td>2025-01-30_1_MBL015</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-01-30\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-27_1_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL014\\2025-06-27</td>\n",
       "      <td>Z:/MBL014\\2025-06-27\\1\\2025-06-27_1_MBL014_Blo...</td>\n",
       "      <td>2025-06-27_1_MBL014</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-06-27\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-06-27_2_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL014\\2025-06-27</td>\n",
       "      <td>Z:/MBL014\\2025-06-27\\2\\2025-06-27_2_MBL014_Blo...</td>\n",
       "      <td>2025-06-27_2_MBL014</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-06-27\\2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-27_3_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL014\\2025-06-27</td>\n",
       "      <td>Z:/MBL014\\2025-06-27\\3\\2025-06-27_3_MBL014_Blo...</td>\n",
       "      <td>2025-06-27_3_MBL014</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-06-27\\3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-30_1_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL014\\2025-06-30</td>\n",
       "      <td>Z:/MBL014\\2025-06-30\\1\\2025-06-30_1_MBL014_Blo...</td>\n",
       "      <td>2025-06-30_1_MBL014</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-06-30\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-07-01_1_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Z:/MBL014\\2025-07-01</td>\n",
       "      <td>Z:/MBL014\\2025-07-01\\1\\2025-07-01_1_MBL014_Blo...</td>\n",
       "      <td>2025-07-01_1_MBL014</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-07-01\\1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    animalID recordingDate recordingID          sessionName  learningData  \\\n",
       "0     MBL015    2025-01-24           1  2025-01-24_1_MBL015         False   \n",
       "1     MBL015    2025-01-27           1  2025-01-27_1_MBL015         False   \n",
       "2     MBL015    2025-01-28           1  2025-01-28_1_MBL015         False   \n",
       "3     MBL015    2025-01-29           1  2025-01-29_1_MBL015         False   \n",
       "4     MBL015    2025-01-30           1  2025-01-30_1_MBL015         False   \n",
       "..       ...           ...         ...                  ...           ...   \n",
       "220   MBL014    2025-06-27           1  2025-06-27_1_MBL014         False   \n",
       "221   MBL014    2025-06-27           2  2025-06-27_2_MBL014         False   \n",
       "222   MBL014    2025-06-27           3  2025-06-27_3_MBL014         False   \n",
       "223   MBL014    2025-06-30           1  2025-06-30_1_MBL014         False   \n",
       "224   MBL014    2025-07-01           1  2025-07-01_1_MBL014         False   \n",
       "\n",
       "      twoP                  path  \\\n",
       "0    False  Z:/MBL015\\2025-01-24   \n",
       "1    False  Z:/MBL015\\2025-01-27   \n",
       "2    False  Z:/MBL015\\2025-01-28   \n",
       "3    False  Z:/MBL015\\2025-01-29   \n",
       "4    False  Z:/MBL015\\2025-01-30   \n",
       "..     ...                   ...   \n",
       "220  False  Z:/MBL014\\2025-06-27   \n",
       "221  False  Z:/MBL014\\2025-06-27   \n",
       "222  False  Z:/MBL014\\2025-06-27   \n",
       "223  False  Z:/MBL014\\2025-06-30   \n",
       "224  False  Z:/MBL014\\2025-07-01   \n",
       "\n",
       "                                   sessionNameWithPath            blockName  \\\n",
       "0    Z:/MBL015\\2025-01-24\\1\\2025-01-24_1_MBL015_Blo...  2025-01-24_1_MBL015   \n",
       "1    Z:/MBL015\\2025-01-27\\1\\2025-01-27_1_MBL015_Blo...  2025-01-27_1_MBL015   \n",
       "2    Z:/MBL015\\2025-01-28\\1\\2025-01-28_1_MBL015_Blo...  2025-01-28_1_MBL015   \n",
       "3    Z:/MBL015\\2025-01-29\\1\\2025-01-29_1_MBL015_Blo...  2025-01-29_1_MBL015   \n",
       "4    Z:/MBL015\\2025-01-30\\1\\2025-01-30_1_MBL015_Blo...  2025-01-30_1_MBL015   \n",
       "..                                                 ...                  ...   \n",
       "220  Z:/MBL014\\2025-06-27\\1\\2025-06-27_1_MBL014_Blo...  2025-06-27_1_MBL014   \n",
       "221  Z:/MBL014\\2025-06-27\\2\\2025-06-27_2_MBL014_Blo...  2025-06-27_2_MBL014   \n",
       "222  Z:/MBL014\\2025-06-27\\3\\2025-06-27_3_MBL014_Blo...  2025-06-27_3_MBL014   \n",
       "223  Z:/MBL014\\2025-06-30\\1\\2025-06-30_1_MBL014_Blo...  2025-06-30_1_MBL014   \n",
       "224  Z:/MBL014\\2025-07-01\\1\\2025-07-01_1_MBL014_Blo...  2025-07-01_1_MBL014   \n",
       "\n",
       "    imagingTiffFileNames                                   analysispathname  \\\n",
       "0                         C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "1                         C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "2                         C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "3                         C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "4                         C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "..                   ...                                                ...   \n",
       "220                       C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "221                       C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "222                       C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "223                       C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "224                       C:/Users/Lak Lab/Documents/Github/sideBiasLate...   \n",
       "\n",
       "               filepathname  \n",
       "0    Z:/MBL015\\2025-01-24\\1  \n",
       "1    Z:/MBL015\\2025-01-27\\1  \n",
       "2    Z:/MBL015\\2025-01-28\\1  \n",
       "3    Z:/MBL015\\2025-01-29\\1  \n",
       "4    Z:/MBL015\\2025-01-30\\1  \n",
       "..                      ...  \n",
       "220  Z:/MBL014\\2025-06-27\\1  \n",
       "221  Z:/MBL014\\2025-06-27\\2  \n",
       "222  Z:/MBL014\\2025-06-27\\3  \n",
       "223  Z:/MBL014\\2025-06-30\\1  \n",
       "224  Z:/MBL014\\2025-07-01\\1  \n",
       "\n",
       "[225 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1> load the environment + define the path\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#make data file\n",
    "print( \"Takes <30s. However, it might take >1 mins or so if network is busy...\")\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import main_funcs as mfun\n",
    "import utils_funcs as utils # utils is from Vape - catcher file: \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Get the list of recordings\n",
    "info = mfun.analysis()\n",
    "# display the detected session\n",
    "print( \"Total Session: \" +  str(info.recordingList .shape[0]))\n",
    "#info.recordingList.head()\n",
    "\n",
    "# set matlab API\n",
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "print('Matlab engine is set correctly.')\n",
    "\n",
    "info.recordingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animalID</th>\n",
       "      <th>recordingDate</th>\n",
       "      <th>recordingID</th>\n",
       "      <th>sessionName</th>\n",
       "      <th>learningData</th>\n",
       "      <th>twoP</th>\n",
       "      <th>path</th>\n",
       "      <th>sessionNameWithPath</th>\n",
       "      <th>blockName</th>\n",
       "      <th>imagingTiffFileNames</th>\n",
       "      <th>analysispathname</th>\n",
       "      <th>filepathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-14_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Z:/MBL015\\2025-05-14</td>\n",
       "      <td>Z:/MBL015\\2025-05-14\\1\\2025-05-14_1_MBL015_Blo...</td>\n",
       "      <td>2025-05-14_1_MBL015</td>\n",
       "      <td>Z:/MBL015\\2025-05-14\\TwoP\\2025-05-14_t-001</td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-05-14\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-20_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Z:/MBL015\\2025-05-20</td>\n",
       "      <td>Z:/MBL015\\2025-05-20\\1\\2025-05-20_1_MBL015_Blo...</td>\n",
       "      <td>2025-05-20_1_MBL015</td>\n",
       "      <td>Z:/MBL015\\2025-05-20\\TwoP\\2025-05-20_t-001</td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-05-20\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MBL015</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-22_1_MBL015</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Z:/MBL015\\2025-05-22</td>\n",
       "      <td>Z:/MBL015\\2025-05-22\\1\\2025-05-22_1_MBL015_Blo...</td>\n",
       "      <td>2025-05-22_1_MBL015</td>\n",
       "      <td>Z:/MBL015\\2025-05-22\\TwoP\\2025-05-22_t-001</td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL015\\2025-05-22\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-18_1_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Z:/MBL014\\2025-06-18</td>\n",
       "      <td>Z:/MBL014\\2025-06-18\\1\\2025-06-18_1_MBL014_Blo...</td>\n",
       "      <td>2025-06-18_1_MBL014</td>\n",
       "      <td>Z:/MBL014\\2025-06-18\\TwoP\\2025-06-18_t-001</td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-06-18\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-19_1_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Z:/MBL014\\2025-06-19</td>\n",
       "      <td>Z:/MBL014\\2025-06-19\\1\\2025-06-19_1_MBL014_Blo...</td>\n",
       "      <td>2025-06-19_1_MBL014</td>\n",
       "      <td>Z:/MBL014\\2025-06-19\\TwoP\\2025-06-19_t-001</td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-06-19\\1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MBL014</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-21_1_MBL014</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Z:/MBL014\\2025-06-21</td>\n",
       "      <td>Z:/MBL014\\2025-06-21\\1\\2025-06-21_1_MBL014_Blo...</td>\n",
       "      <td>2025-06-21_1_MBL014</td>\n",
       "      <td>Z:/MBL014\\2025-06-21\\TwoP\\2025-06-21_t-001</td>\n",
       "      <td>C:/Users/Lak Lab/Documents/Github/sideBiasLate...</td>\n",
       "      <td>Z:/MBL014\\2025-06-21\\1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animalID recordingDate recordingID          sessionName  learningData  twoP  \\\n",
       "0   MBL015    2025-05-14           1  2025-05-14_1_MBL015         False  True   \n",
       "1   MBL015    2025-05-20           1  2025-05-20_1_MBL015         False  True   \n",
       "2   MBL015    2025-05-22           1  2025-05-22_1_MBL015         False  True   \n",
       "3   MBL014    2025-06-18           1  2025-06-18_1_MBL014         False  True   \n",
       "4   MBL014    2025-06-19           1  2025-06-19_1_MBL014         False  True   \n",
       "5   MBL014    2025-06-21           1  2025-06-21_1_MBL014         False  True   \n",
       "\n",
       "                   path                                sessionNameWithPath  \\\n",
       "0  Z:/MBL015\\2025-05-14  Z:/MBL015\\2025-05-14\\1\\2025-05-14_1_MBL015_Blo...   \n",
       "1  Z:/MBL015\\2025-05-20  Z:/MBL015\\2025-05-20\\1\\2025-05-20_1_MBL015_Blo...   \n",
       "2  Z:/MBL015\\2025-05-22  Z:/MBL015\\2025-05-22\\1\\2025-05-22_1_MBL015_Blo...   \n",
       "3  Z:/MBL014\\2025-06-18  Z:/MBL014\\2025-06-18\\1\\2025-06-18_1_MBL014_Blo...   \n",
       "4  Z:/MBL014\\2025-06-19  Z:/MBL014\\2025-06-19\\1\\2025-06-19_1_MBL014_Blo...   \n",
       "5  Z:/MBL014\\2025-06-21  Z:/MBL014\\2025-06-21\\1\\2025-06-21_1_MBL014_Blo...   \n",
       "\n",
       "             blockName                        imagingTiffFileNames  \\\n",
       "0  2025-05-14_1_MBL015  Z:/MBL015\\2025-05-14\\TwoP\\2025-05-14_t-001   \n",
       "1  2025-05-20_1_MBL015  Z:/MBL015\\2025-05-20\\TwoP\\2025-05-20_t-001   \n",
       "2  2025-05-22_1_MBL015  Z:/MBL015\\2025-05-22\\TwoP\\2025-05-22_t-001   \n",
       "3  2025-06-18_1_MBL014  Z:/MBL014\\2025-06-18\\TwoP\\2025-06-18_t-001   \n",
       "4  2025-06-19_1_MBL014  Z:/MBL014\\2025-06-19\\TwoP\\2025-06-19_t-001   \n",
       "5  2025-06-21_1_MBL014  Z:/MBL014\\2025-06-21\\TwoP\\2025-06-21_t-001   \n",
       "\n",
       "                                    analysispathname            filepathname  \n",
       "0  C:/Users/Lak Lab/Documents/Github/sideBiasLate...  Z:/MBL015\\2025-05-14\\1  \n",
       "1  C:/Users/Lak Lab/Documents/Github/sideBiasLate...  Z:/MBL015\\2025-05-20\\1  \n",
       "2  C:/Users/Lak Lab/Documents/Github/sideBiasLate...  Z:/MBL015\\2025-05-22\\1  \n",
       "3  C:/Users/Lak Lab/Documents/Github/sideBiasLate...  Z:/MBL014\\2025-06-18\\1  \n",
       "4  C:/Users/Lak Lab/Documents/Github/sideBiasLate...  Z:/MBL014\\2025-06-19\\1  \n",
       "5  C:/Users/Lak Lab/Documents/Github/sideBiasLate...  Z:/MBL014\\2025-06-21\\1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of sessions to filter\n",
    "#specific_expRefs = ['2025-05-20_1_MBL015', '2025-05-22_1_MBL015', '2025-05-14_1_MBL015']\n",
    "#specific_expRefs = ['2025-06-13_3_MBL014', '2025-06-18_1_MBL014', '2025-06-19_1_MBL014']\n",
    "\n",
    "specific_expRefs = ['2025-06-18_1_MBL014', '2025-06-19_1_MBL014', '2025-05-20_1_MBL015', '2025-05-22_1_MBL015', '2025-05-14_1_MBL015', '2025-06-21_1_MBL014']\n",
    "#specific_expRefs = ['2025-06-21_1_MBL014']\n",
    "\n",
    "# Filter the recording list to include only the specified sessions\n",
    "info.recordingList = info.recordingList[info.recordingList['sessionName'].isin(specific_expRefs)].reset_index(drop=True)\n",
    "info.recordingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization completed and saved for session 2025-06-21_1_MBL014\n",
      "Saved to: C:/Users/Lak Lab/Documents/Github/sideBiasLateralisation\\analysis\\2025-06-21_MBL014_1\\2025-06-21_1_MBL014_behavior_plot.png\n"
     ]
    }
   ],
   "source": [
    "#2>  create + save beh fig\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    session = str(info.recordingList.sessionName[ind])  # Usar ind en lugar de 0\n",
    "    save_path = info.recordingList.analysispathname[ind]  # Usar ind en lugar de 0\n",
    "    save_file = os.path.join(save_path, f\"{session}_behavior_plot.png\")\n",
    "\n",
    "    # Check if file already exists\n",
    "    if os.path.exists(save_file):\n",
    "        print(f\"File already exists for session {session}, skipping visualization\")\n",
    "        print(f\"Existing file: {save_file}\")\n",
    "    else:\n",
    "        try:\n",
    "            # Create figure and get handle\n",
    "            eng.visualiseTrainingGrating2AFC(session, 'Grating2AFC_noTimeline', [], nargout=0)\n",
    "            \n",
    "            # Get the current figure handle\n",
    "            fig = eng.gcf()\n",
    "            \n",
    "            # Save the figure\n",
    "            eng.saveas(fig, save_file, nargout=0)\n",
    "            #eng.close(fig, nargout=0)  # Close the figure\n",
    "            \n",
    "            print(f\"Visualization completed and saved for session {session}\")\n",
    "            print(f\"Saved to: {save_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error when running visualiseTrainingGrating2AFC: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paq and creating imaging_frames.txt for session: 2025-06-21_1_MBL014\n",
      "Saved file: Z:/MBL014\\2025-06-21\\TwoP\\2025-06-21_MBL014_1_paq_imaging_frames.txt\n",
      "Saved file: Z:/MBL014\\2025-06-21\\TwoP\\2025-06-21_MBL014_1_paq_reward_frames.txt\n",
      "imaging_frames.txt created successfully for 2025-06-21_MBL014_1_paq.paq\n"
     ]
    }
   ],
   "source": [
    "#3> Extract PAQ data and create imaging frames file\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append('LakLabAnalysis/Utility')  # Asegurarse que el path estÃ¡ en el sistema\n",
    "from extract_paq_events import extract_paq_data_frame\n",
    "\n",
    "# For every session in  recordingList\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    # Build the path to the PAQ file using glob to find any .paq file\n",
    "    paq_path = os.path.join(info.recordingList.path[ind], 'TwoP', '*.paq')\n",
    "    paq_files = glob.glob(paq_path)\n",
    "    \n",
    "    if paq_files:\n",
    "        print(f\"Processing paq and creating imaging_frames.txt for session: {info.recordingList.sessionName[ind]}\")\n",
    "        for paq_file in paq_files:\n",
    "            try:\n",
    "                # Extract data and create imaging_frames.txt\n",
    "                extract_paq_data_frame(paq_file)\n",
    "                print(f\"imaging_frames.txt created successfully for {os.path.basename(paq_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {os.path.basename(paq_file)}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"No paq files found for session: {info.recordingList.sessionName[ind]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting time events--> Profile: Grating2AFC  Session: 2025-06-21_1_MBL014\n",
      " Aligning time events: 2025-06-21_1_MBL014\n",
      "Behaviour trial data extraction completed: 1.0/1\n"
     ]
    }
   ],
   "source": [
    "#4> Check CSV files \n",
    "# checkOnly needs to be False to create new files with MATLAB GENERIC CODE: GetBehavData.mat\n",
    "checkOnly = False # Make false when there is more behaviour session\n",
    "alignSubtract = True\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "\n",
    "    filenameCSV = info.recordingList.analysispathname[ind] + info.recordingList.sessionName[ind] + '_CorrectedeventTimes.csv'\n",
    "    e_filenameCSV = [f for f in glob.glob(filenameCSV)]\n",
    "    if len(e_filenameCSV)==1:\n",
    "        info.recordingList.loc[ind,'eventTimesExtracted']=1\n",
    "        info.recordingList.loc[ind,'eventTimesPath'] = filenameCSV\n",
    "    else:\n",
    "        if checkOnly:\n",
    "            info.recordingList.loc[ind,'eventTimesExtracted']=0\n",
    "            info.recordingList.loc[ind,'eventTimesPath'] = filenameCSV\n",
    "        else:\n",
    "            try:\n",
    "                filenameTimeline = [f for f in glob.glob(info.recordingList.filepathname[ind]+ '\\\\' + info.recordingList.sessionName[ind] + '_Timeline.mat')]\n",
    "                if  (len(filenameTimeline)>0):\n",
    "                    sessionProfile ='Grating2AFC'\n",
    "                else:\n",
    "                    sessionProfile ='Grating2AFC_noTimeline'\n",
    "                \n",
    "                # Get behaviour trial data from Block.mat file\n",
    "                print(' Extracting time events--> Profile: ' + sessionProfile  +'  Session: ' + info.recordingList.sessionName[ind])\n",
    "                data = eng.getBehavData(info.recordingList.sessionName[ind],sessionProfile)\n",
    "\n",
    "                # Apply correction based on the weights to match the eventTimes\n",
    "                if (alignSubtract) & (len(filenameTimeline)>0) & (info.recordingList.twoP[ind]==True): \n",
    "                    print(' Aligning time events: ' + info.recordingList.sessionName[ind])\n",
    "                    # Get weights to convert from probe to behavioural timebase\n",
    "                    twoPpath = info.recordingList.path[ind] + '\\\\TwoP'\n",
    "                    sessionName = info.recordingList.sessionName[ind]\n",
    "                    figsavepath = info.recordingList.analysispathname[ind]\n",
    "                    dataCorrected, variance = eng.applySubtractionCorrection (data, twoPpath ,sessionName, True, figsavepath, nargout=2)\n",
    "                    info.recordingList.loc[ind,'variance'] = variance\n",
    "\n",
    "                    # Apply correction to the signal\n",
    "                    data = dataCorrected\n",
    "                    \n",
    "                # Save the file\n",
    "                eng.writetable(data, filenameCSV, nargout=0)\n",
    "                info.recordingList.loc[ind,'eventTimesExtracted']=1\n",
    "            except:\n",
    "                print(str(ind) + ' - FAILED: Extracting time events: ' + info.recordingList.sessionName[ind])\n",
    "                info.recordingList.loc[ind,'eventTimesExtracted']=0\n",
    "\n",
    "# display the output\n",
    "print( \"Behaviour trial data extraction completed: \" + \n",
    "      str(info.recordingList.eventTimesExtracted.sum()) +\"/\" + str(info.recordingList.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a> SANDRA'S settings for suite2p\n",
    "# for GCaMP6s\n",
    "#diameter_um = 7.9\n",
    "ops = {\n",
    "        'batch_size': 200, # reduce if running out of RAM        \n",
    "        'fast_disk': 'D:\\\\suite2p_binaries',\n",
    "        'delete_bin': False, # whether to delete binary file after processing\n",
    "        'move_bin': True, # moves temp data.bin from fast_disk to save_path if save_path!=fast_disk\n",
    "        'diameter': 14, # this is the main parameter for cell detection, 2-dimensional if Y and X are different (e.g. [6 12])\n",
    "        # main settings\n",
    "        'nplanes' : 1, # each tiff has these many planes in sequence\n",
    "        'nchannels' : 1, # each tiff has these many channels per plane\n",
    "        'functional_chan' : 1, # this channel is used to extract functional ROIs (1-based)\n",
    "        'tau':  1.25, # this is the main parameter for deconvolution (1.25-1.5 for gcamp6s)\n",
    "        'fs': 30, # sampling rate (total across planes, will auto-change from .csv)\n",
    "        # output settings\n",
    "        'save_mat': True, # whether to save output as matlab files\n",
    "        'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "        'save_NWB': 0.0,\n",
    "        'aspect': 1.0,\n",
    "        'do_bidiphase': False,\n",
    "        'bidiphase': 0,\n",
    "        'bidi_corrected': True,\n",
    "\n",
    "        # registration settings\n",
    "        'do_registration': True, # whether to register data\n",
    "        'two_step_registration': 0.0,\n",
    "        'keep_movie_raw': False,\n",
    "        'nimg_init': 500, # subsampled frames for finding reference image\n",
    "        'batch_size': 500,\n",
    "        'maxregshift': 0.1, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "        'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "        'reg_tif': False, # whether to save registered tiffs\n",
    "        'subpixel' : 10, # precision of subpixel registration (1/subpixel steps)\n",
    "        'smooth_sigma_time': 0.0,\n",
    "        'smooth_sigma': 1.15,\n",
    "        'th_badframes': 1.0,\n",
    "        'norm_frames': True,\n",
    "        'force_refImg': False,\n",
    "        'pad_fft': False,\n",
    "\n",
    "        #Non-rigid\n",
    "        'nonrigid': True,\n",
    "        'block_size': [128, 128],\n",
    "        'snr_thresh': 1.2,\n",
    "        'maxregshiftNR': 5.0,\n",
    "\n",
    "        #1P\n",
    "        '1Preg': False,\n",
    "        'spatial_hp_reg': 42.0,\n",
    "        'pre_smooth': 0.0,\n",
    "        'spatial_taper': 40.0,\n",
    "        \n",
    "        # Functional cell detection settings\n",
    "        'roidetect': True,\n",
    "        'spikedetect': True,\n",
    "        'sparse_mode': True,\n",
    "        'spatial_scale': 0,\n",
    "        'connected': True, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "        # 'navg_frames_svd': 5000, # max number of binned frames for the SVD\n",
    "        # 'nsvd_for_roi': 1000, # max number of SVD components to keep for ROI detection\n",
    "        'max_iterations': 30, # maximum number of iterations to do cell detection\n",
    "        # 'ratio_neuropil': 6., # ratio between neuropil basis size and cell radius\n",
    "        # 'ratio_neuropil_to_cell': 3, # minimum ratio between neuropil radius and cell radius\n",
    "        # 'tile_factor': 1., # use finer (>1) or coarser (<1) tiles for neuropil estimation during cell detection\n",
    "        'threshold_scaling': 0, # adjust the automatically determined threshold by this scalar multiplier\n",
    "        'max_overlap': 0.75, # cells with more overlap than this get removed during triage, before refinement\n",
    "        'high_pass': 100.0,\n",
    "        'spatial_hp_detect': 25.0,\n",
    "        'denoise': 0.0,\n",
    "        \n",
    "        #Anatomical detection\n",
    "        'anatomical_only': 3,\n",
    "        #'diameter': [10], #14, #in pixels; be the equivalent of 8 um ? 15 um? \n",
    "        'cellprob_threshold': -6.0,\n",
    "        'flow_threshold': 0.0,\n",
    "        'spatial_hp_cp': 0.0,\n",
    "        'pretrained_model': 'cyto',\n",
    "        \n",
    "        # Extraction/Neuropil & Classify/Deconvolute\n",
    "        'soma_crop': 1.0,\n",
    "        'neuropil_extract': True,\n",
    "        'inner_neuropil_radius': 2,\n",
    "        'min_neuropil_pixels': 350,\n",
    "        # 'lam_percentile': 50.0,  #not listed in ops settings dialog\n",
    "        'allow_overlap': True,\n",
    "        'use_builtin_classifier': False,\n",
    "        'classifier_path': '',\n",
    "        # 'chan2_thres': 0.65, #not listed in ops settings dialog\n",
    "        # 'baseline': 'maximin',  #not listed in ops settings dialog\n",
    "        'win_baseline': 60.0,\n",
    "        'sig_baseline': 10.0,\n",
    "        # 'prctile_baseline': 8.0, #not listed in ops settings dialog\n",
    "        'neucoeff': 0.7,\n",
    "      }\n",
    "ops_mCh = {\n",
    "        #Anatomical detection\n",
    "        'anatomical_only': 4, ##MAX PROJECTION\n",
    "        'diameter': 15, ##STRICTER TO REALLY JUST GET WHOLE CELLS\n",
    "        'cellprob_threshold': -6.0,\n",
    "        'flow_threshold': 1.5, #STRICTER\n",
    "        'spatial_hp_cp': 0.0,\n",
    "        'pretrained_model': 'cyto',\n",
    "      }\n",
    "\n",
    "ops_CTb = {\n",
    "        #Anatomical detection\n",
    "        'anatomical_only': 2, ##Mean PROJECTION\n",
    "        'diameter': 15, ##STRICTER TO REALLY JUST GET WHOLE CELLS\n",
    "        'cellprob_threshold': -6.0,\n",
    "        'flow_threshold': 0, #less strict\n",
    "        'spatial_hp_cp': 0.0,\n",
    "        'pretrained_model': 'cyto',\n",
    "      }\n",
    "\n",
    "#imagingParams_path = os.path.join(info.recordingListPath, \"helperfiles\", \"2025-01_ImagingLogs_SAT017_AMRev.csv\").replace('\\\\', '/')\n",
    "#imagingParams = pd.read_csv(imagingParams_path)\n",
    "#sessionDates = [session[:10] for session in imagingParams['session']]\n",
    "errorLog = []\n",
    "remake = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a> default settings for Suite2p analysis\n",
    "ops = {\n",
    "        'batch_size': 500, # reduce if running out of RAM\n",
    "        'fast_disk': 'D:\\\\suite2p_binaries', # used to store temporary binary file, defaults to save_path0 (set as a string NOT a list)\n",
    "        #'fast_disk': os.path.expanduser('~/suite2p_binaries'), # used to store temporary binary file, defaults to save_path0 (set as a string NOT a list)\n",
    "         #'save_path0': '/media/jamesrowland/DATA/plab/suite_2p', # stores results, defaults to first item in data_path\n",
    "        'delete_bin': False, # whether to delete binary file after processing\n",
    "        # main settings\n",
    "        'nplanes' : 1, # each tiff has these many planes in sequence\n",
    "        'nchannels' : 1, # each tiff has these many channels per plane\n",
    "        'functional_chan' : 1, # this channel is used to extract functional ROIs (1-based)\n",
    "        'diameter': 16, # this is the main parameter for cell detection, 2-dimensional if Y and X are different (e.g. [6 12])\n",
    "        'tau':  1.25, # this is the main parameter for deconvolution (1.25-1.5 for gcamp6s)\n",
    "        'fs': 30.,  # sampling rate (total across planes)\n",
    "        # output settings\n",
    "        'save_mat': True, # whether to save output as matlab files\n",
    "        'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "        # parallel settings\n",
    "        'num_workers': 0, # 0 to select num_cores, -1 to disable parallelism, N to enforce value\n",
    "        'num_workers_roi': 0, # 0 to select number of planes, -1 to disable parallelism, N to enforce value\n",
    "        # registration settings\n",
    "        'do_registration': True, # whether to register data\n",
    "        'nimg_init': 500, # subsampled frames for finding reference image\n",
    "        'maxregshift': 0.1, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "        'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "        'reg_tif': True, # whether to save registered tiffs\n",
    "        'subpixel' : 10, # precision of subpixel registration (1/subpixel steps)\n",
    "        # cell detection settings\n",
    "        'connected': True, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "        #'navg_frames_svd': 5000, # max number of binned frames for the SVD\n",
    "        #'nsvd_for_roi': 1000, # max number of SVD components to keep for ROI detection\n",
    "        'max_iterations': 30, # maximum number of iterations to do cell detection\n",
    "        #'ratio_neuropil': 6., # ratio between neuropil basis size and cell radius\n",
    "        #'ratio_neuropil_to_cell': 3, # minimum ratio between neuropil radius and cell radius\n",
    "        #'tile_factor': 1., # use finer (>1) or coarser (<1) tiles for neuropil estimation during cell detection\n",
    "        'threshold_scaling': 0., # adjust the automatically determined threshold by this scalar multiplier\n",
    "        'max_overlap': 0.75, # cells with more overlap than this get removed during triage, before refinement\n",
    "        'inner_neuropil_radius': 2, # number of pixels to keep between ROI and neuropil donut\n",
    "        'outer_neuropil_radius': np.inf, # maximum neuropil radius\n",
    "        'min_neuropil_pixels': 350, # minimum number of pixels in the neuropil\n",
    "        # deconvolution settings\n",
    "        #'baseline': 'maximin', # baselining mode\n",
    "        'win_baseline': 60., # window for maximin\n",
    "        'sig_baseline': 10., # smoothing constant for gaussian filter\n",
    "        #'prctile_baseline': 8.,# optional (whether to use a percentile baseline)\n",
    "        'neucoeff': .7,  # neuropil coefficient\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b> Run Suite2p\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    # Check if twoP is True\n",
    "    if info.recordingList.twoP[ind]:\n",
    "        tiff_directory = os.path.join(info.recordingList.path[ind], 'TwoP', f\"{info.recordingList.recordingDate[ind]}_t-001\")\n",
    "        suite2p_folder = os.path.join(tiff_directory, 'suite2p')\n",
    "        e_suite2p_folder = [f for f in glob.glob(suite2p_folder)]\n",
    "        if len(e_suite2p_folder)==1:\n",
    "                info.recordingList.loc[ind,'suite2pPath'] = suite2p_folder\n",
    "                print(f\"{info.recordingList.animalID[ind]}{info.recordingList.recordingDate[ind]}: Suite2p is created before\")\n",
    "        else:\n",
    "            db = { \n",
    "                        'data_path':  os.path.join(info.rawPath, info.recordingList.animalID[ind]),\n",
    "                        'tiff_list': glob.glob(os.path.join(tiff_directory, \"*.tif\")),\n",
    "                        'save_folder': suite2p_folder\n",
    "                        }\n",
    "            from suite2p.run_s2p import run_s2p\n",
    "            import time        \n",
    "            t1 = time.time()\n",
    "            opsEnd = run_s2p(ops=ops,db=db)\n",
    "            t2 = time.time()\n",
    "            print(f\"{info.recordingList.animalID[ind]}: Suite2p is created in {t2 - t1} seconds.\")\n",
    "    else:\n",
    "        print(f\"Skipping Suite2p for {info.recordingList.animalID[ind]} - twoP is False\")\n",
    "    \n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting...\n",
      "loading 27 traces labelled as cells\n",
      "subtracting neuropil with a coefficient of 0.7\n",
      "C:/Users/Lak Lab/Documents/Github/sideBiasLateralisation\\analysis\\2025-06-21_MBL014_1\\imaging-data.pkl --> # of cells: 27 # of frames: 107203\n",
      "Successfully saved imaging data for session 2025-06-21_1_MBL014\n"
     ]
    }
   ],
   "source": [
    "#6> extract suite2p output\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    # Define the output file path\n",
    "    filenameINFO = os.path.join(info.recordingList.analysispathname[ind], 'imaging-data.pkl')\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if os.path.exists(filenameINFO):\n",
    "        print(f\"File already exists for session {info.recordingList.sessionName[ind]}, skipping extraction\")\n",
    "        print(f\"Existing file: {filenameINFO}\")\n",
    "    else:\n",
    "        try:\n",
    "            # Read suite2p\n",
    "            s2p_path = os.path.join(info.recordingList.path[ind], 'TwoP', f\"{info.recordingList.recordingDate[ind]}_t-001\", 'suite2p', 'plane0')\n",
    "            if os.path.exists(s2p_path):\n",
    "                print('Extracting...')\n",
    "                ops = np.load(os.path.join(s2p_path, 'ops.npy'), allow_pickle=True)\n",
    "                ops = ops.item()\n",
    "                FrameNums = ops['frames_per_file']\n",
    "                filelist = ops['filelist']\n",
    "                isCell = np.load(os.path.join(s2p_path, 'iscell.npy'), allow_pickle=True)\n",
    "\n",
    "                # Load the suite2p\n",
    "                flu_raw_subtracted, spks, stat = utils.s2p_loader(s2p_path)\n",
    "                flu = utils.dfof2(flu_raw_subtracted)\n",
    "\n",
    "                # Cut each session & save it in the analysis-session folder\n",
    "                imaging_data = {\n",
    "                    \"n_frames\": FrameNums,\n",
    "                    \"flu\": flu,\n",
    "                    \"spks\": spks,\n",
    "                    \"stat\": stat,\n",
    "                }\n",
    "                \n",
    "                print(f\"{filenameINFO} --> # of cells: {flu.shape[0]} # of frames: {flu.shape[1]}\")\n",
    "                with open(filenameINFO, 'wb') as f:\n",
    "                    pickle.dump(imaging_data, f)\n",
    "                print(f\"Successfully saved imaging data for session {info.recordingList.sessionName[ind]}\")\n",
    "            else:\n",
    "                print(f\"Suite2p path not found: {s2p_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {info.recordingList.sessionName[ind]}: {str(e)}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7> Visualize cells\n",
    "# Filter cells with probability > 0.5\n",
    "prob_threshold = 0.5\n",
    "cell_indices = np.where((isCell[:,0] == 1) & (isCell[:,1] > prob_threshold))[0]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Show mean image\n",
    "ax.imshow(ops['meanImg'], cmap='binary_r')\n",
    "\n",
    "# Load stat.npy to get cell coordinates\n",
    "stat = np.load(os.path.join(s2p_path, 'stat.npy'), allow_pickle=True)\n",
    "\n",
    "# Generate random colors for each cell\n",
    "colors = np.random.rand(len(cell_indices), 3)\n",
    "\n",
    "# Draw ROIs of filtered cells\n",
    "for idx, cell_number in enumerate(cell_indices):\n",
    "    stat_cell = stat[cell_number]\n",
    "    ypix = [stat_cell['ypix'][i] for i in range(len(stat_cell['ypix'])) if not stat_cell['overlap'][i]]\n",
    "    xpix = [stat_cell['xpix'][i] for i in range(len(stat_cell['xpix'])) if not stat_cell['overlap'][i]]\n",
    "    ax.plot(xpix, ypix, '.', markersize=1, alpha=0.7, color=colors[idx])\n",
    "\n",
    "ax.set_title(f\"Detected cells (prob > {prob_threshold}): {len(cell_indices)}\")\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Also show enhanced image (meanImgE) which might be clearer\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(ops['meanImgE'], cmap='binary_r')\n",
    "\n",
    "# Draw ROIs of filtered cells\n",
    "for idx, cell_number in enumerate(cell_indices):\n",
    "    stat_cell = stat[cell_number]\n",
    "    ypix = [stat_cell['ypix'][i] for i in range(len(stat_cell['ypix'])) if not stat_cell['overlap'][i]]\n",
    "    xpix = [stat_cell['xpix'][i] for i in range(len(stat_cell['xpix'])) if not stat_cell['overlap'][i]]\n",
    "    ax.plot(xpix, ypix, '.', markersize=1, alpha=0.7, color=colors[idx])\n",
    "\n",
    "ax.set_title(f\"Detected cells (prob > {prob_threshold}): {len(cell_indices)}\")\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imaging data extraction completed: 6.0/6\n"
     ]
    }
   ],
   "source": [
    "#8> Check Suite2p extraction\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    filenameDFF = info.recordingList.analysispathname[ind] + 'imaging-data.pkl'\n",
    "    e_filenameDFF = [f for f in glob.glob(filenameDFF)]\n",
    "    if len(e_filenameDFF)>0:\n",
    "        info.recordingList.loc[ind,'imagingDataExtracted']=1\n",
    "        info.recordingList.loc[ind,'imagingDataPath'] = filenameDFF\n",
    "    else:\n",
    "        info.recordingList.loc[ind,'imagingDataExtracted']=0\n",
    "        info.recordingList.loc[ind,'imagingDataPath'] = filenameDFF\n",
    "\n",
    "# display the output\n",
    "print( \"Imaging data extraction completed: \" + \n",
    "      str(info.recordingList.imagingDataExtracted.sum()) +\"/\" + str(info.recordingList.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9> check imaging-data.pkl\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Iterar sobre cada Ã­ndice en la recording list\n",
    "for ind in range(len(info.recordingList)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing recording {ind+1} of {len(info.recordingList)}\")\n",
    "    print(f\"Session: {info.recordingList.sessionName[ind]}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # File path\n",
    "    file_path = info.recordingList.analysispathname[ind] + 'imaging-data.pkl'\n",
    "    \n",
    "    try:\n",
    "        # Open and load the pickle file\n",
    "        with open(file_path, 'rb') as f:\n",
    "            imaging_data = pickle.load(f)\n",
    "        \n",
    "        # Show the keys of the dictionary\n",
    "        print(\"Keys available in the file:\")\n",
    "        print(imaging_data.keys())\n",
    "        \n",
    "        # Show basic data information\n",
    "        print(\"\\nData information:\")\n",
    "        print(f\"Number of frames: {imaging_data['n_frames']}\")\n",
    "        print(f\"Flu shape: {imaging_data['flu'].shape}\")\n",
    "        print(f\"Spks shape: {imaging_data['spks'].shape}\")\n",
    "        print(f\"Number of elements in stat: {len(imaging_data['stat'])}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found in {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All should be done!!\n"
     ]
    }
   ],
   "source": [
    "#10> Save info into the analysis folder\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump(info, f)\n",
    "print('All should be done!!')\n",
    "\n",
    "# Save table as CSV\n",
    "recordingList = info.recordingList\n",
    "recordingList.to_csv( info.analysisPath +'\\\\recordingList.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sideBias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
